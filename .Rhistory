pwd
# In this file, we'll read the data in and filter it
# The data is in the 'data/' folder
# Written for R version 3.6.1
library(dplyr)
# Load the data
# This is the dataset named 'hauls'
# It has all the information for individual hauls
# in surveys
load('data/master_hauls_March7_2017.RData')
# This is the dataset names 'dat'
# It has all the information for individual species
# per haul
load('data/dat_selectedspp_Feb_1_2017.Rdata')
# Species of interest
# Black sea bass – Centropristis striata
# Summer flounder - Paralichthys dentatus
# Tautog - Tautoga onitis
# Scup (Porgy) - Stenotomus chrysops
# Maybe other species of interest
# Weakfish - Cynoscion regalis
# Blueline tilefish - Caulolatilus microps / Caulolatilus spp.
# Monkfish - Lophius spp.
# All species names in the 'dat' file are appended
# with a regional marker
# Example - centropristis striata_Atl
# Because it's from the Atlantic Ocean
# Filtering out only the needed species
# Species that we are interested in
rec_species <- c('centropristis striata_Atl',
'paralichthys dentatus_Atl',
'tautoga onitis_Atl',
'stenotomus chrysops_Atl',
'Urophycis chuss_Atl',
'Urophycis regia_Atl')
# Filtering the 'dat' dataframe
# sp_data <- dat[dat$sppocean %in% rec_species, ]
sp_data <- dat %>% filter(sppocean %in% rec_species)
# Now let's group the 'sp_data' dataframe and see how many
# observations we have for each species
grouped_sp_data <- sp_data %>% group_by(sppocean)
# Now let's summarize some of the data
print(sp_data %>% count(sppocean))
# Remaining to do
# Merge 'hauls' and 'sp_data'
# Identify the continuous variables
# Conduct preliminary LDA on the data
dat <- dat[!(dat$wtcpue == 0 & dat$region == 'DFO_SoGulf'),]
dat$wtcpue[dat$wtcpue == 0] <- 0.0002
sp_data$logwtcpue <- log(sp_data$wtcpue)
# Select only several relevant columns
sp_data <- sp_data %>% select(haulid, sppocean, Freq, wtcpue, logwtcpue)
# Now we'll merge it with hauls
# We'll use inner join
sp_haul_data <- left_join(sp_data, hauls, by='haulid')
#
sp_not_null <- sp_haul_data %>% filter(!is.na(year))
write.csv(sp_not_null, file="data/data_for_lda.csv")
# In this file, we'll read the data in and filter it
# The data is in the 'data/' folder
# Written for R version 3.6.1
library(dplyr)
# Load the data
# This is the dataset named 'hauls'
# It has all the information for individual hauls
# in surveys
load('data/master_hauls_March7_2017.RData')
# This is the dataset names 'dat'
# It has all the information for individual species
# per haul
load('data/dat_selectedspp_Feb_1_2017.Rdata')
# Species of interest
# Black sea bass – Centropristis striata
# Summer flounder - Paralichthys dentatus
# Tautog - Tautoga onitis
# Scup (Porgy) - Stenotomus chrysops
# Maybe other species of interest
# Weakfish - Cynoscion regalis
# Blueline tilefish - Caulolatilus microps / Caulolatilus spp.
# Monkfish - Lophius spp.
# All species names in the 'dat' file are appended
# with a regional marker
# Example - centropristis striata_Atl
# Because it's from the Atlantic Ocean
# Filtering out only the needed species
# Species that we are interested in
rec_species <- c('centropristis striata_Atl',
'paralichthys dentatus_Atl',
'tautoga onitis_Atl',
'stenotomus chrysops_Atl',
'urophycis chuss_Atl',
'urophycis regia_Atl')
# Filtering the 'dat' dataframe
# sp_data <- dat[dat$sppocean %in% rec_species, ]
sp_data <- dat %>% filter(sppocean %in% rec_species)
# Now let's group the 'sp_data' dataframe and see how many
# observations we have for each species
grouped_sp_data <- sp_data %>% group_by(sppocean)
# Now let's summarize some of the data
print(sp_data %>% count(sppocean))
# Remaining to do
# Merge 'hauls' and 'sp_data'
# Identify the continuous variables
# Conduct preliminary LDA on the data
dat <- dat[!(dat$wtcpue == 0 & dat$region == 'DFO_SoGulf'),]
dat$wtcpue[dat$wtcpue == 0] <- 0.0002
sp_data$logwtcpue <- log(sp_data$wtcpue)
# Select only several relevant columns
sp_data <- sp_data %>% select(haulid, sppocean, Freq, wtcpue, logwtcpue)
# Now we'll merge it with hauls
# We'll use inner join
sp_haul_data <- left_join(sp_data, hauls, by='haulid')
#
sp_not_null <- sp_haul_data %>% filter(!is.na(year))
write.csv(sp_not_null, file="data/data_for_lda.csv")
# In this file, we'll read the data in and filter it
# The data is in the 'data/' folder
# Written for R version 3.6.1
library(dplyr)
# Load the data
# This is the dataset named 'hauls'
# It has all the information for individual hauls
# in surveys
load('data/master_hauls_March7_2017.RData')
# This is the dataset names 'dat'
# It has all the information for individual species
# per haul
load('data/dat_selectedspp_Feb_1_2017.Rdata')
# Species of interest
# Black sea bass – Centropristis striata
# Summer flounder - Paralichthys dentatus
# Tautog - Tautoga onitis
# Scup (Porgy) - Stenotomus chrysops
# Maybe other species of interest
# Weakfish - Cynoscion regalis
# Blueline tilefish - Caulolatilus microps / Caulolatilus spp.
# Monkfish - Lophius spp.
# All species names in the 'dat' file are appended
# with a regional marker
# Example - centropristis striata_Atl
# Because it's from the Atlantic Ocean
# Filtering out only the needed species
# Species that we are interested in
rec_species <- c('centropristis striata_Atl',
'paralichthys dentatus_Atl',
'tautoga onitis_Atl',
'stenotomus chrysops_Atl',
'urophycis chuss_Atl',
'urophycis regia_Atl')
# Filtering the 'dat' dataframe
# sp_data <- dat[dat$sppocean %in% rec_species, ]
sp_data <- dat %>% filter(sppocean %in% rec_species)
# Now let's group the 'sp_data' dataframe and see how many
# observations we have for each species
grouped_sp_data <- sp_data %>% group_by(sppocean)
# Now let's summarize some of the data
print(sp_data %>% count(sppocean))
# Remaining to do
# Merge 'hauls' and 'sp_data'
# Identify the continuous variables
# Conduct preliminary LDA on the data
dat <- dat[!(dat$wtcpue == 0 & dat$region == 'DFO_SoGulf'),]
dat$wtcpue[dat$wtcpue == 0] <- 0.0002
sp_data$logwtcpue <- log(sp_data$wtcpue)
# Select only several relevant columns
sp_data <- sp_data %>% select(haulid, sppocean, Freq, wtcpue, logwtcpue)
# Now we'll merge it with hauls
# We'll use inner join
sp_haul_data <- left_join(sp_data, hauls, by='haulid')
#
sp_not_null <- sp_haul_data %>% filter(!is.na(year))
write.csv(sp_not_null, file="data/data_for_analysis_i.csv")
# In this file we'll perform the full analysis on the
# geofiltered values for the Northern Atlantic stocks of
# black sea bass, summer flounder, and scup
# Written for R Version 3.6.1
library(tidyverse)
library(MASS)
library(lattice)
# Read in the data
sp_obs_data <- read.csv("data/all_species_mid_atlantic_bight.csv")
# Re-check to see if the data is structured as required
# How many unique species are in the dataset?
print(unique(sp_obs_data$sppocean))
# In this file we'll perform the full analysis on the
# geofiltered values for the Northern Atlantic stocks of
# black sea bass, summer flounder, and scup
# Written for R Version 3.6.1
library(tidyverse)
library(MASS)
library(lattice)
# Read in the data
sp_obs_data <- read.csv("data/all_species_mid_atlantic_bight.csv")
# Re-check to see if the data is structured as required
# How many unique species are in the dataset?
print(unique(sp_obs_data$sppocean))
# The answer is 3
# Assigning seasons to the observations based on the month
sp_obs_data[, "season"] <- NA
# February to June is Spring
sp_obs_data$season[sp_obs_data$month %in% c(2,3,4,5)] <- 'Spring'
# June to September is Summer
sp_obs_data$season[sp_obs_data$month %in% c(6,7,8)] <- 'Summer'
# September to January is Fall
sp_obs_data$season[sp_obs_data$month %in% c(9,10,11,12)] <- 'Fall'
# Assigning common names to the species
# First an empty column
sp_obs_data[, "spp_name"] <- NA
sp_obs_data$spp_name[sp_obs_data$sppocean == 'centropristis striata_Atl'] <- 'black sea bass'
sp_obs_data$spp_name[sp_obs_data$sppocean == 'paralichthys dentatus_Atl'] <- 'summer flounder'
sp_obs_data$spp_name[sp_obs_data$sppocean == 'stenotomus chrysops_Atl'] <- 'scup'
sp_obs_data$spp_name[sp_obs_data$sppocean == 'urophycis chuss_Atl'] <- 'red hake'
sp_obs_data$spp_name[sp_obs_data$sppocean == 'urophycis regia_Atl'] <- 'spotted hake'
View(sp_obs_data)
# First let's begin discriminator analysis for species between seasons
# LDA formula for seasons
seasons_lda_formula <- formula(season ~ SBT.seasonal + SST.seasonal.mean + SBT.min + SBT.max + SST.max + rugosity + GRAINSIZE)
# Now let's see if they can discrminate between the species in a single season
# My guess is probably not, but we'll see
# Formula for species
species_lda_formula <- formula(spp_name ~ SBT.seasonal + SST.seasonal.mean + SBT.min + SBT.max + SST.max + rugosity + GRAINSIZE)
species_lda_formula_2 <- formula(spp_name ~ rugosity + GRAINSIZE)
# First let's go for fall
# Filter the season
sp_obs_fall <- sp_obs_data %>% filter(season=='Fall')
# Derive the discriminant functions
sp_lda_fall <- lda(species_lda_formula, data = sp_obs_fall)
# Apply the discriminant functions to the data to get DF scores
lda_values_fall <- predict(sp_lda_fall)
lda_df_fall <- data.frame(lda_values_fall$x[,1], lda_values_fall$x[,2], sp_obs_fall$spp_name)
# Rename the columns
columns <- c("LD1", "LD2","spp_name")
colnames(lda_df_fall) <- columns
# Plot the discriminant functions
ggplot(lda_df_fall, aes(x=LD1, y=LD2)) +
geom_point(aes(color = factor(spp_name)), show.legend=FALSE) +
xlab("DF1 (87.24%)") + ylab("DF2 (12.76%)") +
ggtitle("Fall") + theme(plot.title = element_text(hjust = 0.5))
ggsave("output/fall_lda.png")
# Next let's go for spring
sp_obs_spring <- sp_obs_data %>% filter(season=='Spring')
# Derive the discriminant functions
sp_lda_spring <- lda(species_lda_formula, data = sp_obs_spring)
# Apply the discriminant functions to the data to get DF scores
lda_values_spring <- predict(sp_lda_spring)
lda_df_spring <- data.frame(lda_values_spring$x[,1], lda_values_spring$x[,2], sp_obs_spring$spp_name)
# Rename the columns
columns <- c("LD1", "LD2","spp_name")
colnames(lda_df_spring) <- columns
# Plot the discriminant functions
ggplot(lda_df_spring, aes(x=LD1, y=LD2)) +
geom_point(aes(color = factor(spp_name)), show.legend=FALSE) +
xlab("DF1 (87.96%)") + ylab("DF2 (12.04%)") +
ggtitle("Spring") + theme(plot.title = element_text(hjust = 0.5))
ggsave("output/spring_lda.png")
# Write out the CSV
write_csv(sp_obs_data, path="data/all_species_mid_atlantic_bight_output_common_names.csv")
View(sp_lda_spring)
View(sp_lda_spring)
lda_values_fall
predict(lda_values_fall, dimen=2)$x
View(lda_df_fall)
lda_values_fall$x
predict(sp_lda_fall)
lda(species_lda_formula, data = sp_obs_fall)
lda(species_lda_formula, data = sp_obs_spring)
# In this file we'll perform the full analysis on the
# geofiltered values for the Northern Atlantic stocks of
# black sea bass, summer flounder, and scup
# Written for R Version 3.6.1
library(tidyverse)
library(MASS)
library(lattice)
# Read in the data
sp_obs_data <- read.csv("data/all_species_mid_atlantic_bight.csv")
# Re-check to see if the data is structured as required
# How many unique species are in the dataset?
print(unique(sp_obs_data$sppocean))
# The answer is 3
# Assigning seasons to the observations based on the month
sp_obs_data[, "season"] <- NA
# February to June is Spring
sp_obs_data$season[sp_obs_data$month %in% c(2,3,4,5)] <- 'Spring'
# June to September is Summer
sp_obs_data$season[sp_obs_data$month %in% c(6,7,8)] <- 'Summer'
# September to January is Fall
sp_obs_data$season[sp_obs_data$month %in% c(9,10,11,12)] <- 'Fall'
# Assigning common names to the species
# First an empty column
sp_obs_data[, "spp_name"] <- NA
sp_obs_data$spp_name[sp_obs_data$sppocean == 'centropristis striata_Atl'] <- 'black sea bass'
sp_obs_data$spp_name[sp_obs_data$sppocean == 'paralichthys dentatus_Atl'] <- 'summer flounder'
sp_obs_data$spp_name[sp_obs_data$sppocean == 'stenotomus chrysops_Atl'] <- 'scup'
sp_obs_data$spp_name[sp_obs_data$sppocean == 'urophycis chuss_Atl'] <- 'red hake'
sp_obs_data$spp_name[sp_obs_data$sppocean == 'urophycis regia_Atl'] <- 'spotted hake'
# We must first run a Bartlett's test for this
# First let's begin discriminator analysis for species between seasons
# LDA formula for seasons
seasons_lda_formula <- formula(season ~ SBT.seasonal + SST.seasonal.mean + SBT.min + SBT.max + SST.max + rugosity + GRAINSIZE)
# It seems that the discriminant functions are doing a good job of discriminating between seasons
# for individual species
# Now let's see if they can discrminate between the species in a single season
# My guess is probably not, but we'll see
# Formula for species
species_lda_formula <- formula(spp_name ~ SBT.seasonal + SST.seasonal.mean + SBT.min + SBT.max + SST.max + rugosity + GRAINSIZE)
species_lda_formula_2 <- formula(spp_name ~ rugosity + GRAINSIZE)
# First let's go for fall
# Filter the season
sp_obs_fall <- sp_obs_data %>% filter(season=='Fall')
# Derive the discriminant functions
sp_lda_fall <- lda(species_lda_formula, data = sp_obs_fall)
# Apply the discriminant functions to the data to get DF scores
lda_values_fall <- predict(sp_lda_fall)
lda_df_fall <- data.frame(lda_values_fall$x[,1], lda_values_fall$x[,2], sp_obs_fall$spp_name)
# Rename the columns
columns <- c("LD1", "LD2","spp_name")
colnames(lda_df_fall) <- columns
# Plot the discriminant functions
ggplot(lda_df_fall, aes(x=LD1, y=LD2)) +
geom_point(aes(color = factor(spp_name)), show.legend=FALSE) +
xlab("DF1 (81.06%)") + ylab("DF2 (18.52%)") +
ggtitle("Fall") + theme(plot.title = element_text(hjust = 0.5))
ggsave("output/fall_lda.png")
# Correlation between df scores and variables
# cor(sp_obs_bsb[c("SST.seasonal.mean","SBT.seasonal","SBT.min","SBT.max","rugosity", "GRAINSIZE")], lda_values_bsb$x)
# Next let's go for spring
sp_obs_spring <- sp_obs_data %>% filter(season=='Spring')
# Derive the discriminant functions
sp_lda_spring <- lda(species_lda_formula, data = sp_obs_spring)
# Apply the discriminant functions to the data to get DF scores
lda_values_spring <- predict(sp_lda_spring)
lda_df_spring <- data.frame(lda_values_spring$x[,1], lda_values_spring$x[,2], sp_obs_spring$spp_name)
# Rename the columns
columns <- c("LD1", "LD2","spp_name")
colnames(lda_df_spring) <- columns
# Plot the discriminant functions
ggplot(lda_df_spring, aes(x=LD1, y=LD2)) +
geom_point(aes(color = factor(spp_name)), show.legend=FALSE) +
xlab("DF1 (76.14%)") + ylab("DF2 (16.43%)") +
ggtitle("Spring") + theme(plot.title = element_text(hjust = 0.5))
ggsave("output/spring_lda.png")
# As can be seen from the plots, the fact that these species share similar habitats throughout the year
# is well reflected graphically through discrminant analysis
# Write out the CSV
write_csv(sp_obs_data, path="data/all_species_mid_atlantic_bight_output_common_names.csv")
# Plot the discriminant functions
ggplot(lda_df_spring, aes(x=LD1, y=LD2)) +
geom_point(aes(color = factor(spp_name)), show.legend=FALSE) +
xlab("DF1 (76.14%)") + ylab("DF2 (16.43%)") +
ggtitle("Spring") + theme(plot.title = element_text(hjust = 0.5), legend.position = 'right')
ggplot(lda_df_spring, aes(x=LD1, y=LD2)) +
geom_point(aes(color = factor(spp_name)), show.legend=TRUE) +
xlab("DF1 (76.14%)") + ylab("DF2 (16.43%)") +
ggtitle("Spring") + theme(plot.title = element_text(hjust = 0.5), legend.position = 'right')
# Plot the discriminant functions
ggplot(lda_df_fall, aes(x=LD1, y=LD2)) +
geom_point(aes(color = factor(spp_name)), show.legend=TRUE) +
xlab("DF1 (81.06%)") + ylab("DF2 (18.52%)") +
ggtitle("Fall") + theme(plot.title = element_text(hjust = 0.5))
